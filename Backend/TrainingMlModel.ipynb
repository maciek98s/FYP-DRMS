{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainingMlModel.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1EcXD8Kg0CIhRhfduQqy3hJnwWQkuX6n5","authorship_tag":"ABX9TyN9S3XN6A7IC0rqZHCxu5Wv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QYZYFeMUVcyQ"},"source":["\r\n","\r\n","\r\n","# Training Machine learning model"]},{"cell_type":"code","metadata":{"id":"iD6D9dOV-yoJ","executionInfo":{"status":"ok","timestamp":1615354788137,"user_tz":0,"elapsed":927,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["import numpy as np\r\n","\r\n","from keras.applications.inception_v3 import InceptionV3\r\n","from keras.applications.inception_v3 import preprocess_input, decode_predictions\r\n","import cv2\r\n","from tensorflow.python.keras.preprocessing import image\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","import pandas as pd\r\n","import numpy as np\r\n","import os\r\n","import keras\r\n","from sklearn.model_selection import train_test_split\r\n","from keras.layers import Input,GlobalAveragePooling2D,Dropout,Dense,Activation,Flatten\r\n","from keras import applications\r\n","from keras.applications import ResNet50\r\n","from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\r\n","from keras import optimizers,Model,Sequential\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib.image  as mpimg\r\n","from multiprocessing.pool import ThreadPool\r\n","from keras.models import load_model\r\n","from keras.layers import Conv2D, MaxPooling2D\r\n","from keras.utils import to_categorical\r\n","%matplotlib inline\r\n","from tqdm import tqdm\r\n","from prettytable import PrettyTable\r\n","import pickle\r\n","import multiprocessing\r\n","import seaborn as sns\r\n","plt.rcParams[\"axes.grid\"] = False\r\n","from sklearn.metrics import confusion_matrix, cohen_kappa_score,accuracy_score\r\n","from PIL import Image\r\n","from keras.models import model_from_json\r\n","\r\n","\r\n","\r\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1gVHhCxdp5ZC"},"source":["# The Functions\r\n","the program uses various functions to deal with different activties throughout in order to successfully train the machine learning model \r\n"]},{"cell_type":"code","metadata":{"id":"ka7_jjwoWScY","executionInfo":{"status":"ok","timestamp":1615354791351,"user_tz":0,"elapsed":795,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["#This Function loads the train/test data from a folder and cvs file into variables\r\n","def load_data():\r\n","    train = pd.read_csv('train.csv')\r\n","    test = pd.read_csv('test.csv')\r\n","    \r\n","    train_dir = os.path.join('./','train_images/')\r\n","    test_dir = os.path.join('./','test_images/')\r\n","    \r\n","    train['file_path'] = train['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\r\n","    test['file_path'] = test['id_code'].map(lambda x: os.path.join(test_dir,'{}.png'.format(x)))\r\n","    \r\n","    train['file_name'] = train[\"id_code\"].apply(lambda x: x + \".png\")\r\n","    test['file_name'] = test[\"id_code\"].apply(lambda x: x + \".png\")\r\n","    \r\n","    train['diagnosis'] = train['diagnosis'].astype(str)\r\n","    \r\n","    return train,test"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6w73eimOqeLj"},"source":["These next Functions deal with Processing The Images to produce an results of higher accuracy \r\n"]},{"cell_type":"code","metadata":{"id":"yALKY-pKWcjJ","executionInfo":{"status":"ok","timestamp":1615354793595,"user_tz":0,"elapsed":901,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["'''Function loads an image from Folder , Resizes and saves in another directory '''\r\n","\r\n","def image_resize_save(values):\r\n","    for i in values:\r\n","      input_filepath = os.path.join('./','test_images','{}'.format(i))\r\n","      output_filepath = os.path.join('./','test_images_resized','{}'.format(i))\r\n","      img = cv2.imread(input_filepath)\r\n","      cv2.imwrite(output_filepath, cv2.resize(img, (IMG_SIZE,IMG_SIZE)))\r\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"nuwCAtniZB_9","executionInfo":{"status":"ok","timestamp":1615354795757,"user_tz":0,"elapsed":1037,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["\r\n","def crop_image_from_gray(img,tol=7):\r\n","    if img.ndim ==2:\r\n","        mask = img>tol\r\n","        return img[np.ix_(mask.any(1),mask.any(0))]\r\n","    elif img.ndim==3:\r\n","        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\r\n","        mask = gray_img>tol\r\n","        \r\n","        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\r\n","        if (check_shape == 0): # image is too dark so that we crop out everything,\r\n","            return img # return original image\r\n","        else:\r\n","            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\r\n","            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\r\n","            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\r\n","    #         print(img1.shape,img2.shape,img3.shape)\r\n","            img = np.stack([img1,img2,img3],axis=-1)\r\n","    #         print(img.shape)\r\n","        return img\r\n","\r\n","def circle_crop(img, sigmaX = 30):   \r\n","    \"\"\"\r\n","    Create circular crop around image centre    \r\n","    \"\"\"    \r\n","    img = crop_image_from_gray(img)    \r\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n","    \r\n","    height, width, depth = img.shape    \r\n","    \r\n","    x = int(width/2)\r\n","    y = int(height/2)\r\n","    r = np.amin((x,y))\r\n","    \r\n","    circle_img = np.zeros((height, width), np.uint8)\r\n","    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\r\n","    img = cv2.bitwise_and(img, img, mask=circle_img)\r\n","    img = crop_image_from_gray(img)\r\n","    img=cv2.addWeighted(img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\r\n","    return img \r\n","\r\n","def preprocess_image(values):\r\n","    for i in values: \r\n","      input_filepath = os.path.join('./','train_images_resized','{}'.format(i))\r\n","      output_filepath = os.path.join('./','train_images_resized_preprocessed','{}'.format(i))\r\n","      \r\n","      img = cv2.imread(input_filepath)\r\n","      height, width, channels = img.shape\r\n","      img = circle_crop(img) \r\n","      cv2.imwrite(output_filepath, cv2.resize(img, (IMG_SIZE,IMG_SIZE)))\r\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FgoFycaqqoPv"},"source":["Next Functions are used to successfully train the model\r\n"]},{"cell_type":"code","metadata":{"id":"fqf6YwHIZL_C","executionInfo":{"status":"ok","timestamp":1615354798532,"user_tz":0,"elapsed":698,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["def img_generator(train,test):\r\n","    train_datagen=ImageDataGenerator(rescale=1./255, validation_split=0.2,horizontal_flip=True)\r\n","    \r\n","    train_generator=train_datagen.flow_from_dataframe(dataframe=df_train_train,\r\n","                                                      directory=\"./train_images_resized_preprocessed/\",\r\n","                                                      x_col=\"file_name\",\r\n","                                                      y_col=\"diagnosis\",\r\n","                                                      batch_size=BATCH_SIZE,\r\n","                                                      class_mode=\"categorical\",\r\n","                                                      target_size=(HEIGHT, WIDTH),\r\n","                                                      subset='training')\r\n","    \r\n","    valid_generator=train_datagen.flow_from_dataframe(dataframe=df_train_train,\r\n","                                                      directory=\"./train_images_resized_preprocessed/\",\r\n","                                                      x_col=\"file_name\",\r\n","                                                      y_col=\"diagnosis\",\r\n","                                                      batch_size=BATCH_SIZE,\r\n","                                                      class_mode=\"categorical\",    \r\n","                                                      target_size=(HEIGHT, WIDTH),\r\n","                                                      subset='validation')\r\n","    \r\n","    test_datagen = ImageDataGenerator(rescale=1./255)\r\n","    test_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\r\n","                                                      directory = \"./test_images_resized_preprocessed/\",\r\n","                                                      x_col=\"file_name\",\r\n","                                                      target_size=(HEIGHT, WIDTH),\r\n","                                                      batch_size=1,\r\n","                                                      shuffle=False,\r\n","                                                      class_mode=None)\r\n","    \r\n","    return train_generator,valid_generator,test_generator"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"FoAmT_nnZPqu","executionInfo":{"status":"ok","timestamp":1615354801255,"user_tz":0,"elapsed":979,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["def create_model(input_shape, n_out):\r\n","    input_tensor = Input(shape=input_shape)\r\n","    base_model = applications.ResNet50(weights=\"imagenet\", include_top=False,input_tensor=input_tensor)\r\n","\r\n","    x = GlobalAveragePooling2D()(base_model.output)\r\n","    x = Dropout(0.5)(x)\r\n","    x = Dense(2048, activation='relu')(x)\r\n","    x = Dropout(0.5)(x)\r\n","    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\r\n","    model = Model(input_tensor, final_output)\r\n","    return model"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9TYCMXgcqw9x"},"source":["Main code of the program underneath declaring variables and using the functions to process the images and train the model "]},{"cell_type":"code","metadata":{"id":"UEC36ILbq4sV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VdeIY1OYZjJy","executionInfo":{"status":"ok","timestamp":1615354803068,"user_tz":0,"elapsed":891,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["IMG_SIZE = 512\r\n","BATCH_SIZE = 8\r\n","EPOCHS = 25\r\n","WARMUP_EPOCHS = 2\r\n","LEARNING_RATE = 1e-4\r\n","WARMUP_LEARNING_RATE = 1e-3\r\n","HEIGHT = 320\r\n","WIDTH = 320\r\n","CANAL = 3\r\n","\r\n","ES_PATIENCE = 5\r\n","RLROP_PATIENCE = 3\r\n","DECAY_DROP = 0.5"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0eByuVMm5gN","executionInfo":{"status":"ok","timestamp":1615354805175,"user_tz":0,"elapsed":905,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["train_dir = \"train_images/\"\r\n","val_dir   = \"backend/test_images/\" #directories for training\r\n","\r\n","test_dir  = \"backend/val/\" #directory for final model scoring"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udnvI_YNm9VN","executionInfo":{"status":"ok","timestamp":1615354806942,"user_tz":0,"elapsed":564,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}},"outputId":"65a7cb4d-d603-47e0-d992-e0522062c297"},"source":["os.chdir('/content/drive/MyDrive/Colab Notebooks')\r\n","print(\"We are currently in the folder of \",os.getcwd())\r\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["We are currently in the folder of  /content/drive/MyDrive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_K3i-JEDzSpP"},"source":["df_train,df_test = load_data()\r\n","print(df_train.shape,df_test.shape,'\\n')\r\n","df_test.head(6)\r\n","image_resize_save(df_test.file_name.values)\r\n","preprocess_image(df_train.file_name.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vcLQVe5gzUwO"},"source":["df_train_train,df_train_valid = train_test_split(df_train,test_size = 0.2)\r\n","print(df_train_train.shape,df_train_valid.shape)\r\n","df_train_train.head(6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3-AoBCMvzXLO","executionInfo":{"status":"ok","timestamp":1615334541172,"user_tz":0,"elapsed":559,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":["N_CLASSES = df_train_train['diagnosis'].nunique()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ky4ZQxNKzgZF"},"source":["train_generator,valid_generator,test_generator = img_generator(df_train_train,df_train_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwZOfj5GzmMZ"},"source":["model = create_model(input_shape=(HEIGHT, WIDTH, CANAL), n_out=N_CLASSES)\r\n","\r\n","for layer in model.layers:\r\n","    layer.trainable = False\r\n","\r\n","for i in range(-5, 0):\r\n","    model.layers[i].trainable = True\r\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SwTDXOfMzrc1"},"source":["STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\r\n","STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\r\n","print(STEP_SIZE_TRAIN,STEP_SIZE_VALID)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuaWW-MNzt2C"},"source":["model.compile(optimizer = optimizers.Adam(lr=WARMUP_LEARNING_RATE),loss = 'categorical_crossentropy',metrics = ['accuracy'])\r\n","\r\n","history_warmup = model.fit_generator(generator=train_generator,\r\n","                                     steps_per_epoch=STEP_SIZE_TRAIN,\r\n","                                     validation_data=valid_generator,validation_steps=STEP_SIZE_VALID,\r\n","                                     epochs=WARMUP_EPOCHS,\r\n","                                     verbose=1).history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUmURCYNi1MK"},"source":["\r\n","\r\n","for layer in model.layers:\r\n","    layer.trainable = True\r\n","\r\n","es = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\r\n","rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\r\n","\r\n","callback_list = [es, rlrop]\r\n","optimizer = optimizers.Adam(lr=LEARNING_RATE)\r\n","model.compile(optimizer=optimizer, loss=\"binary_crossentropy\",  metrics=['accuracy'])\r\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"trDfioHXi_1Y"},"source":["checkpoint = ModelCheckpoint(\"test_best_model.h5\", monitor='loss', verbose=1,\r\n","    save_best_only=True, mode='auto', period=1)\r\n","\r\n","history_finetunning = model.fit_generator(generator=train_generator,\r\n","                                          steps_per_epoch=STEP_SIZE_TRAIN,\r\n","                                          validation_data=valid_generator,\r\n","                                          validation_steps=STEP_SIZE_VALID,\r\n","                                          epochs=EPOCHS,\r\n","                                          callbacks= [checkpoint],\r\n","                                          verbose=1).history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gWNhY56pzzj"},"source":["plt.figure(figsize=(8,5))\r\n","\r\n","plt.plot(history_finetunning['accuracy'])\r\n","plt.plot(history_finetunning['val_accuracy'])\r\n","plt.title('Model Accuracy')\r\n","plt.ylabel('Accuracy')\r\n","plt.xlabel('Epoch')\r\n","plt.legend(['Train', 'Validation'], loc='upper left')\r\n","plt.gca().ticklabel_format(axis='both', style='plain', useOffset=False)\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJcKcL8I8yyS"},"source":["complete_datagen = ImageDataGenerator(rescale=1./255)\r\n","complete_generator = complete_datagen.flow_from_dataframe(dataframe=df_train_train,\r\n","                                                          directory = \"./train_images_resized_preprocessed/\",\r\n","                                                          x_col=\"file_name\",\r\n","                                                          target_size=(HEIGHT, WIDTH),\r\n","                                                          batch_size=1,\r\n","                                                          shuffle=False,\r\n","                                                          class_mode=None)\r\n","\r\n","STEP_SIZE_COMPLETE = complete_generator.n//complete_generator.batch_size\r\n","train_preds = model.predict_generator(complete_generator, steps=STEP_SIZE_COMPLETE,verbose = 1)\r\n","train_preds = [np.argmax(pred) for pred in train_preds]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8RxKdjg_Rvg","executionInfo":{"status":"ok","timestamp":1611015213376,"user_tz":0,"elapsed":589,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}},"outputId":"d95f0cb3-6f46-4014-f6ac-c8dc8d650ced"},"source":["print(\"Train Cohen Kappa score: %.3f\" % cohen_kappa_score(train_preds, df_train_train['diagnosis'].astype('int'), weights='quadratic'))\r\n","print(\"Train Accuracy score : %.3f\" % accuracy_score(df_train_train['diagnosis'].astype('int'),train_preds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Cohen Kappa score: 0.883\n","Train Accuracy score : 0.835\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HZkOY9hCGPTx","executionInfo":{"status":"ok","timestamp":1615353402328,"user_tz":0,"elapsed":1090,"user":{"displayName":"Maciej Skrzypczynski","photoUrl":"","userId":"03243330789890958177"}}},"source":[""],"execution_count":1,"outputs":[]}]}